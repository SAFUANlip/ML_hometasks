{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjl6x6og3uXH"
   },
   "source": [
    "# HW 2 - Разложение матриц градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv79QFb_-oNZ"
   },
   "source": [
    "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом освоить pyTorch и реализовать подходы оптимизации параметров модели (в отсутствии готовых решений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HUSrylpBwYn"
   },
   "source": [
    "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1PuoBtG7iw7",
    "outputId": "2cf68d00-5d67-4036-ef4b-df87be14d253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1043fd250>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import tensorly\n",
    "from tensorly import decomposition\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
    "from scipy.linalg import eigh, eig\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LfhKpuX7htE"
   },
   "source": [
    "## 1 Создайте 3х мерный тензор\n",
    "Размер тензора не меньше 100 по каждой из размерностей.\n",
    "\n",
    "Заполните случайными целыми числами в диапазоне от 0 до 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap1Ozn7P8-Yj"
   },
   "source": [
    "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(tensor, mode):\n",
    "    return torch.reshape(torch.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1))\n",
    "\n",
    "def fold(tensor, mode, shape):\n",
    "    full_shape = list(shape)\n",
    "    mode_shape = full_shape.pop(mode)\n",
    "    full_shape.insert(0, mode_shape)\n",
    "    return torch.moveaxis(torch.reshape(tensor, full_shape), 0, mode)\n",
    "\n",
    "def my_composition(G_, U):\n",
    "    data = G_.clone()\n",
    "    for i in range(len(U)):\n",
    "        init_shape = list(data.shape)\n",
    "        new_shape = init_shape.copy()\n",
    "        new_shape[i] = U[i].shape[0]\n",
    "        G_i = unfold(data,i)\n",
    "        data = fold((U[i]@G_i), i, new_shape);\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5SzHzteOROQQ"
   },
   "outputs": [],
   "source": [
    "def get_tensor(size=(100, 200, 300), r=10):\n",
    "    U = [torch.randint(0,10,(s, r)).float() for s in size]\n",
    "    G = torch.randint(0,10,(r, r, r)).float()\n",
    "    data = my_composition(G, U)\n",
    "    return data, U, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (100,200,300)\n",
    "r = 10\n",
    "\n",
    "data, U, G = get_tensor(size, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFuFlp2n78Tz"
   },
   "source": [
    "Сгенерируйте тензор и добавьте к нему случайный шум с размерностью *1e-2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N70Xy_6u9RFa"
   },
   "outputs": [],
   "source": [
    "noise = torch.rand(data.shape)/10\n",
    "ndata = noise.add(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp75_Ad29RL5"
   },
   "source": [
    "Вопрос:\n",
    "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VLMaT5wyE11"
   },
   "source": [
    "Ответ: если тензор случайный, то он может не иметь разложения\n",
    "и еще мы не сможем проверить ошибку восстановления ядра и матриц, если не будет делать их\n",
    "шум - что-то вроде регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzninpMYD_hd"
   },
   "source": [
    "## 2 Реализуйте метод для восстановления тензора по разложению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKqzxtaE-F16"
   },
   "source": [
    "## 3 Сделайте разложение библиотечным методом\n",
    "Пакет можете брать любой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hlp4Jh3--fKh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 200, 300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tG, tU= tensorly.decomposition.tucker(tensorly.tensor(ndata), G.shape)\n",
    "tdata = torch.tensor(tensorly.tenalg.multi_mode_dot(tG, tU))\n",
    "tdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMw1x8w8-lsh"
   },
   "source": [
    "Не забудьте померить ошибку разложения по метрике MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_loss tucker lib = 0.0010155184006124896\n"
     ]
    }
   ],
   "source": [
    "print(f'mse_loss tucker lib = {torch.sum((tdata-ndata)**2)/torch.numel(tdata)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Реализуйте разложение градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Реализуйте *optimizer*\n",
    "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*.\n",
    "Используйте квадратичный *Loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class Opt(Optimizer):\n",
    "\n",
    "    def __init__(self, data, G, U, batch_size, lr=4e-4):\n",
    "        self.data = data \n",
    "        self.batch_size = batch_size\n",
    "        params = [G, *U]\n",
    "        defaults = {\"lr\": lr}\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        grad = None\n",
    "        while grad is None:\n",
    "            l = len(self.param_groups[0]['params'])\n",
    "            tensor = self.param_groups[0]['params'][np.random.randint(l)]\n",
    "            grad = tensor.grad\n",
    "\n",
    "        if not self.state:\n",
    "            self.state[\"step\"] = 1\n",
    "        else:\n",
    "            self.state[\"step\"] += 1\n",
    "            \n",
    "        if self.state[\"step\"] % 100 == 0:\n",
    "            self.param_groups[0]['lr'] *= 1.005\n",
    "            \n",
    "        if self.state[\"step\"] % 1000 == 0:\n",
    "            self.param_groups[0]['lr'] *= 1.5\n",
    "            \n",
    "            \n",
    "        elems = random.sample(range(1, tensor.numel()), self.batch_size)\n",
    "\n",
    "        mask_flat = torch.zeros(tensor.numel())\n",
    "        mask_flat[elems] = 1\n",
    "        mask = mask_flat.reshape(tensor.shape)\n",
    "        \n",
    "        tensor.data.add_(grad * mask, alpha=-self.param_groups[0]['lr'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Реализуйте цикл оптимизации параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_loop(G, U, data, opt, itr, eps):\n",
    "    loss_history = []\n",
    "   \n",
    "    for i in range(itr):\n",
    "        loss = mse_loss(my_composition(G,U), data)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        if i%400 == 0:\n",
    "            print(f'itr {i} mse is {loss.data}')\n",
    "            \n",
    "        if loss < eps:\n",
    "            break\n",
    "            \n",
    "        loss_history.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
    "Сравнение может считаться ± объективным с размером выборки от 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = (100,200,300)\n",
    "r = 10\n",
    "itr = 50000\n",
    "lr = 1*10**-9\n",
    "eps = 0.5\n",
    "batch_size = 700\n",
    "\n",
    "data, U, G = get_tensor(size, r)\n",
    "noise = torch.rand(data.shape) / 10\n",
    "data = noise.add(data)\n",
    "\n",
    "G_opt = torch.randint(0, 10, (r, r, r)).float().requires_grad_()\n",
    "U_opt = [torch.randint(0, 10, (s, r)).float().requires_grad_() for s in size]\n",
    "\n",
    "my_optimizer = Opt(data, G_opt, U_opt, batch_size, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr 0 mse is 42835152896.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m whole_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\n",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(G, U, data, opt, itr, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(itr):\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m mse_loss(my_composition(G,U), data)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      8\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "loss_history = training_loop(G_opt, U_opt, data, my_optimizer, itr, eps)\n",
    "\n",
    "whole_time = time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tG, tU= tensorly.decomposition.tucker(tensorly.tensor(data), G.shape)\n",
    "tdata = torch.tensor(tensorly.tenalg.multi_mode_dot(tG, tU))\n",
    "print(f'mse for lib optimizer: {mse_loss(tdata, data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = torch.tensor(repair_tensor(G_opt, U_opt))\n",
    "print(f'mse for my optimizer: {mse_loss(data_opt, data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
